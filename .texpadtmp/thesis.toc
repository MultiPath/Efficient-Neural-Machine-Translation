\contentsline {chapter}{Abstract}{iv}{chapter*.1}
\contentsline {chapter}{Acknowledgments}{vi}{chapter*.2}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}A Brief Review of Machine Translation (MT)}{1}{section.1.1}
\contentsline {paragraph}{Rule-based MT}{1}{section*.7}
\contentsline {paragraph}{Example-based MT}{2}{section*.8}
\contentsline {paragraph}{Statistical MT}{2}{section*.9}
\contentsline {paragraph}{Neural MT}{3}{section*.10}
\contentsline {section}{\numberline {1.2}Towards Efficient Neural Machine Translation}{3}{section.1.2}
\contentsline {section}{\numberline {1.3}Thesis Outline}{5}{section.1.3}
\contentsline {chapter}{\numberline {2}Background}{8}{chapter.2}
\contentsline {section}{\numberline {2.1}Modeling}{8}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Neural Language Modeling}{8}{subsection.2.1.1}
\contentsline {paragraph}{Autoregressive Language Model}{9}{section*.13}
\contentsline {paragraph}{Parameterization}{9}{section*.14}
\contentsline {subsection}{\numberline {2.1.2}Sequence-to-Sequence Learning}{10}{subsection.2.1.2}
\contentsline {paragraph}{Neural Machine Translation as {{\textsc {Seq2Seq}}}\xspace Learning}{10}{section*.15}
\contentsline {subsection}{\numberline {2.1.3}Attention Mechanism}{11}{subsection.2.1.3}
\contentsline {subsection}{\numberline {2.1.4}Neural Machine Translation without RNNs}{12}{subsection.2.1.4}
\contentsline {section}{\numberline {2.2}Training}{12}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Data}{12}{subsection.2.2.1}
\contentsline {paragraph}{Parallel corpora}{12}{section*.18}
\contentsline {paragraph}{Vocabulary and Sub-word level translation}{13}{section*.19}
\contentsline {subsection}{\numberline {2.2.2}Maximum Likelihood Learning}{14}{subsection.2.2.2}
\contentsline {section}{\numberline {2.3}Decoding}{14}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Greedy Decoding}{15}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Beam Search}{15}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Noisy Parallel Decoding}{16}{subsection.2.3.3}
\contentsline {part}{I\hspace {1em}Data-Efficient Neural Machine Translation}{18}{part.1}
\contentsline {chapter}{\numberline {3}Copying Mechanism}{19}{chapter.3}
\contentsline {section}{\numberline {3.1}Overview}{19}{section.3.1}
\contentsline {section}{\numberline {3.2}{\textsc {CopyNet}}\xspace }{20}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Model Overview}{21}{subsection.3.2.1}
\contentsline {paragraph}{Encoder:}{21}{section*.21}
\contentsline {paragraph}{Decoder:}{21}{section*.22}
\contentsline {subsection}{\numberline {3.2.2}Prediction with Copying and Generation}{22}{subsection.3.2.2}
\contentsline {paragraph}{Generate-Mode:}{23}{section*.23}
\contentsline {paragraph}{Copy-Mode:}{23}{section*.24}
\contentsline {subsection}{\numberline {3.2.3}State Update}{24}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Hybrid Addressing of Short-Term Memory}{25}{subsection.3.2.4}
\contentsline {paragraph}{Location-based Addressing}{25}{section*.26}
\contentsline {paragraph}{Handling Out-of-Vocabulary Words}{26}{section*.27}
\contentsline {section}{\numberline {3.3}Learning}{26}{section.3.3}
\contentsline {section}{\numberline {3.4}Experiments}{26}{section.3.4}
\contentsline {subsection}{\numberline {3.4.1}Synthetic Dataset}{27}{subsection.3.4.1}
\contentsline {paragraph}{Experimental Setting}{27}{section*.29}
\contentsline {subsection}{\numberline {3.4.2}Text Summarization}{28}{subsection.3.4.2}
\contentsline {paragraph}{Dataset}{29}{section*.32}
\contentsline {paragraph}{Experimental Setting}{29}{section*.34}
\contentsline {paragraph}{Case Study}{30}{section*.37}
\contentsline {subsection}{\numberline {3.4.3}Single-turn Dialogue}{32}{subsection.3.4.3}
\contentsline {paragraph}{Dataset}{32}{section*.38}
\contentsline {paragraph}{Experimental Setting}{32}{section*.39}
\contentsline {paragraph}{Case Study}{33}{section*.42}
\contentsline {section}{\numberline {3.5}Related Work}{34}{section.3.5}
\contentsline {section}{\numberline {3.6}Conclusion and Next Chapter}{35}{section.3.6}
\contentsline {chapter}{\numberline {4}Non-Parametric Neural Machine Translation}{36}{chapter.4}
\contentsline {section}{\numberline {4.1}Overview}{36}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Background: Translation Memory}{38}{subsection.4.1.1}
\contentsline {section}{\numberline {4.2}Search Engine Guided Non-Parametric Neural Machine Translation}{39}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Retrieval Stage}{40}{subsection.4.2.1}
\contentsline {paragraph}{Similarity score function $\ensuremath {\mathcal {S}}$}{40}{section*.45}
\contentsline {paragraph}{Off-the-shelf Search Engine}{40}{section*.46}
\contentsline {paragraph}{Final selection process}{41}{section*.47}
\contentsline {subsection}{\numberline {4.2.2}Translation Stage}{41}{subsection.4.2.2}
\contentsline {paragraph}{Key-Value Memory}{42}{section*.48}
\contentsline {paragraph}{Matching and Retrieval}{42}{section*.49}
\contentsline {paragraph}{Incorporation}{43}{section*.50}
\contentsline {paragraph}{Coverage}{43}{section*.51}
\contentsline {section}{\numberline {4.3}Learning and Inference}{45}{section.4.3}
\contentsline {section}{\numberline {4.4}Experiments}{45}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}Settings}{45}{subsection.4.4.1}
\contentsline {paragraph}{Data}{45}{section*.52}
\contentsline {paragraph}{Retrieval Stage}{46}{section*.54}
\contentsline {paragraph}{Translation Stage}{46}{section*.55}
\contentsline {subsection}{\numberline {4.4.2}Result and Analysis}{47}{subsection.4.4.2}
\contentsline {paragraph}{Fuzzy matching score v.s. Quality}{48}{section*.57}
\contentsline {paragraph}{Effect of the \# of Retrieved Translation Pairs}{48}{section*.60}
\contentsline {paragraph}{Deep vs. Shallow Fusion}{49}{section*.61}
\contentsline {paragraph}{Examples}{49}{section*.62}
\contentsline {paragraph}{Efficiency}{49}{section*.64}
\contentsline {section}{\numberline {4.5}Related Work}{51}{section.4.5}
\contentsline {section}{\numberline {4.6}Conclusion and Next Chapter}{52}{section.4.6}
\contentsline {chapter}{\numberline {5}Universal Neural Machine Translation}{54}{chapter.5}
\contentsline {section}{\numberline {5.1}Overview}{54}{section.5.1}
\contentsline {section}{\numberline {5.2}Motivation: Low-Resource NMT}{55}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Multi-lingual NMT}{56}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Challenges}{57}{subsection.5.2.2}
\contentsline {paragraph}{Lexical-level Sharing}{57}{section*.66}
\contentsline {paragraph}{Sentence-level Sharing}{58}{section*.68}
\contentsline {section}{\numberline {5.3}Universal Neural Machine Translation}{58}{section.5.3}
\contentsline {subsection}{\numberline {5.3.1}Universal Lexical Representation (ULR)}{58}{subsection.5.3.1}
\contentsline {paragraph}{Lexicon Mapping to the Universal Token Space}{59}{section*.70}
\contentsline {paragraph}{Shared Monolingual Embeddings}{60}{section*.71}
\contentsline {paragraph}{Interpolated Embeddings}{61}{section*.73}
\contentsline {paragraph}{An Example}{62}{section*.74}
\contentsline {subsection}{\numberline {5.3.2}Mixture of Language Experts (MoLE)}{62}{subsection.5.3.2}
\contentsline {section}{\numberline {5.4}Experiments}{63}{section.5.4}
\contentsline {subsection}{\numberline {5.4.1}Settings}{63}{subsection.5.4.1}
\contentsline {paragraph}{Dataset}{63}{section*.75}
\contentsline {paragraph}{Preprocessing}{64}{section*.78}
\contentsline {paragraph}{Architecture}{65}{section*.79}
\contentsline {paragraph}{Learning}{65}{section*.80}
\contentsline {subsection}{\numberline {5.4.2}Back-Translation}{65}{subsection.5.4.2}
\contentsline {subsection}{\numberline {5.4.3}Preliminary Experiments}{66}{subsection.5.4.3}
\contentsline {paragraph}{Training Monolingual Embeddings}{66}{section*.81}
\contentsline {paragraph}{Pre-projection}{66}{section*.82}
\contentsline {subsection}{\numberline {5.4.4}Results}{66}{subsection.5.4.4}
\contentsline {paragraph}{Ablation Study}{68}{section*.86}
\contentsline {paragraph}{Monolingual Data}{69}{section*.88}
\contentsline {paragraph}{Corpus Size}{69}{section*.91}
\contentsline {paragraph}{Unknown Tokens}{70}{section*.92}
\contentsline {subsection}{\numberline {5.4.5}Qualitative Analysis}{70}{subsection.5.4.5}
\contentsline {paragraph}{Examples}{70}{section*.93}
\contentsline {paragraph}{Visualization of MoLE}{71}{section*.94}
\contentsline {section}{\numberline {5.5}Related Work}{71}{section.5.5}
\contentsline {section}{\numberline {5.6}Conclusion and Next Chapter}{72}{section.5.6}
\contentsline {chapter}{\numberline {6}Meta Learning for Neural Machine Translation}{73}{chapter.6}
\contentsline {section}{\numberline {6.1}Overview}{73}{section.6.1}
\contentsline {section}{\numberline {6.2}Background: Meta-Learning}{74}{section.6.2}
\contentsline {section}{\numberline {6.3}Meta-Learning for Extremely Low-Resource Neural Machine Translation}{75}{section.6.3}
\contentsline {subsection}{\numberline {6.3.1}Learn: language-specific learning}{75}{subsection.6.3.1}
\contentsline {subsection}{\numberline {6.3.2}MetaLearn}{77}{subsection.6.3.2}
\contentsline {paragraph}{Meta-Gradient}{78}{section*.96}
\contentsline {paragraph}{Related Work: Multilingual Transfer Learning}{79}{section*.97}
\contentsline {paragraph}{Illustration}{79}{figure.6.2}
\contentsline {subsection}{\numberline {6.3.3}Unified Lexical Representation}{80}{subsection.6.3.3}
\contentsline {paragraph}{I/O mismatch across language pairs}{80}{section*.100}
\contentsline {paragraph}{Universal Lexical Representation (ULR)}{80}{section*.101}
\contentsline {paragraph}{Learning of ULR}{81}{section*.102}
\contentsline {section}{\numberline {6.4}Experiments}{81}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Dataset}{81}{subsection.6.4.1}
\contentsline {paragraph}{Target Tasks}{81}{section*.103}
\contentsline {paragraph}{Source Tasks}{82}{section*.105}
\contentsline {paragraph}{Validation}{82}{section*.106}
\contentsline {paragraph}{Preprocessing and ULR Initialization}{82}{section*.107}
\contentsline {subsection}{\numberline {6.4.2}Model and Learning}{83}{subsection.6.4.2}
\contentsline {paragraph}{Model}{83}{section*.108}
\contentsline {paragraph}{Learning}{83}{section*.109}
\contentsline {paragraph}{Fine-tuning Strategies}{83}{section*.110}
\contentsline {subsection}{\numberline {6.4.3}Results}{84}{subsection.6.4.3}
\contentsline {paragraph}{vs. Multilingual Transfer Learning}{84}{section*.112}
\contentsline {paragraph}{Impact of Validation Tasks}{85}{section*.113}
\contentsline {paragraph}{Training Set Size}{86}{section*.115}
\contentsline {paragraph}{Impact of Source Tasks}{86}{section*.119}
\contentsline {paragraph}{Training Curves}{86}{section*.120}
\contentsline {paragraph}{Sample Translations}{88}{section*.121}
\contentsline {section}{\numberline {6.5}Conclusion and Next Chapter}{89}{section.6.5}
\contentsline {part}{II\hspace {1em}Decoding-Efficient Neural Machine Translation}{90}{part.2}
\contentsline {chapter}{\numberline {7}Trainable Greedy Decoding}{91}{chapter.7}
\contentsline {section}{\numberline {7.1}Overview}{91}{section.7.1}
\contentsline {section}{\numberline {7.2}Trainable Greedy Decoding}{93}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Many Decoding Objectives}{93}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Trainable Greedy Decoding}{94}{subsection.7.2.2}
\contentsline {paragraph}{Related Work: Soothsayer prediction function}{95}{section*.123}
\contentsline {subsection}{\numberline {7.2.3}Learning and Challenges}{95}{subsection.7.2.3}
\contentsline {section}{\numberline {7.3}Deterministic Policy Gradient with Critic-Aware Actor Learning}{96}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Deterministic Policy Gradient}{96}{subsection.7.3.1}
\contentsline {subsection}{\numberline {7.3.2}Critic-Aware Actor Learning}{97}{subsection.7.3.2}
\contentsline {paragraph}{Challenges}{97}{section*.124}
\contentsline {paragraph}{Critic-Aware Actor Learning}{97}{section*.125}
\contentsline {paragraph}{Reference Translations for Training the Critic}{99}{section*.126}
\contentsline {section}{\numberline {7.4}Experiments}{101}{section.7.4}
\contentsline {subsection}{\numberline {7.4.1}Settings}{101}{subsection.7.4.1}
\contentsline {paragraph}{Underlying NMT Model}{101}{section*.128}
\contentsline {paragraph}{Actor $\pi $}{101}{section*.129}
\contentsline {paragraph}{Critic $R^c$}{101}{section*.130}
\contentsline {paragraph}{Learning}{102}{section*.131}
\contentsline {paragraph}{Decoding Objectives}{102}{section*.132}
\contentsline {paragraph}{Evaluation}{102}{section*.133}
\contentsline {subsection}{\numberline {7.4.2}Results and Analysis}{103}{subsection.7.4.2}
\contentsline {paragraph}{Importance of Critic-Aware Actor Learning}{103}{section*.137}
\contentsline {paragraph}{Examples}{106}{section*.138}
\contentsline {section}{\numberline {7.5}Conclusion and Next Chapter}{106}{section.7.5}
\contentsline {chapter}{\numberline {8}Non-Autoregressive Neural Machine Translation}{107}{chapter.8}
\contentsline {section}{\numberline {8.1}Overview}{107}{section.8.1}
\contentsline {section}{\numberline {8.2}Non-Autoregressive Decoding}{108}{section.8.2}
\contentsline {paragraph}{Pros and cons of autoregressive decoding}{108}{section*.140}
\contentsline {paragraph}{Towards non-autoregressive decoding}{109}{section*.141}
\contentsline {subsection}{\numberline {8.2.1}The Multimodality Problem}{109}{subsection.8.2.1}
\contentsline {section}{\numberline {8.3}The Non-Autoregressive Transformer (NAT)}{110}{section.8.3}
\contentsline {subsection}{\numberline {8.3.1}Encoder Stack}{111}{subsection.8.3.1}
\contentsline {subsection}{\numberline {8.3.2}Decoder Stack}{111}{subsection.8.3.2}
\contentsline {paragraph}{Decoder Inputs}{111}{section*.143}
\contentsline {paragraph}{Non-causal self-attention}{112}{section*.144}
\contentsline {paragraph}{Positional attention}{112}{section*.145}
\contentsline {subsection}{\numberline {8.3.3}Modeling Fertility to Tackle the Multimodality Problem}{112}{subsection.8.3.3}
\contentsline {paragraph}{Latent Variable Model}{112}{section*.146}
\contentsline {paragraph}{Latent Fertility Model}{113}{section*.147}
\contentsline {paragraph}{Fertility prediction}{114}{section*.148}
\contentsline {paragraph}{Benefits of fertility}{114}{section*.149}
\contentsline {subsection}{\numberline {8.3.4}Translation Predictor and the Decoding Process}{115}{subsection.8.3.4}
\contentsline {paragraph}{Argmax decoding}{115}{section*.150}
\contentsline {paragraph}{Average decoding}{115}{section*.151}
\contentsline {paragraph}{Noisy / Exact parallel decoding (NPD/EPD)}{115}{section*.152}
\contentsline {section}{\numberline {8.4}Learning}{116}{section.8.4}
\contentsline {subsection}{\numberline {8.4.1}Sequence-Level Knowledge Distillation}{117}{subsection.8.4.1}
\contentsline {subsection}{\numberline {8.4.2}Fine-Tuning}{117}{subsection.8.4.2}
\contentsline {section}{\numberline {8.5}Experiments}{118}{section.8.5}
\contentsline {subsection}{\numberline {8.5.1}Settings}{118}{subsection.8.5.1}
\contentsline {paragraph}{Dataset}{118}{section*.153}
\contentsline {paragraph}{Teacher Model}{119}{section*.155}
\contentsline {paragraph}{Preparation for knowledge distillation}{119}{section*.157}
\contentsline {paragraph}{Encoder initialization}{119}{section*.158}
\contentsline {paragraph}{Fertility supervision during training}{120}{section*.159}
\contentsline {paragraph}{Hyperparameters}{120}{section*.160}
\contentsline {paragraph}{Evaluation}{120}{section*.161}
\contentsline {paragraph}{Implementation}{121}{section*.162}
\contentsline {subsection}{\numberline {8.5.2}Results}{121}{subsection.8.5.2}
\contentsline {paragraph}{Ablation Study}{121}{section*.164}
\contentsline {paragraph}{Examples}{122}{section*.170}
\contentsline {subsection}{\numberline {8.5.3}Analysis and Schematic}{125}{subsection.8.5.3}
\contentsline {section}{\numberline {8.6}Conclusion and Next Chapter}{125}{section.8.6}
\contentsline {chapter}{\numberline {9}Simultaneous Neural Machine Translation}{127}{chapter.9}
\contentsline {section}{\numberline {9.1}Overview}{127}{section.9.1}
\contentsline {section}{\numberline {9.2}Problem Definition: Simultaneous Translation}{129}{section.9.2}
\contentsline {section}{\numberline {9.3}Simultaneous Neural Machine Translation}{130}{section.9.3}
\contentsline {subsection}{\numberline {9.3.1}Environment}{130}{subsection.9.3.1}
\contentsline {paragraph}{Encoder:\nobreakspace {}\textsc {read}}{130}{section*.174}
\contentsline {paragraph}{Decoder:\nobreakspace {}\textsc {write}}{131}{section*.175}
\contentsline {subsection}{\numberline {9.3.2}Agent}{131}{subsection.9.3.2}
\contentsline {paragraph}{Observation}{131}{section*.176}
\contentsline {paragraph}{Action}{132}{section*.177}
\contentsline {paragraph}{Policy}{132}{section*.178}
\contentsline {section}{\numberline {9.4}Learning}{132}{section.9.4}
\contentsline {subsection}{\numberline {9.4.1}Pre-training}{132}{subsection.9.4.1}
\contentsline {subsection}{\numberline {9.4.2}Reward Function}{133}{subsection.9.4.2}
\contentsline {paragraph}{Quality}{133}{section*.179}
\contentsline {paragraph}{Delay}{134}{section*.180}
\contentsline {paragraph}{Trade-off between quality and delay}{135}{section*.181}
\contentsline {subsection}{\numberline {9.4.3}Reinforcement Learning}{135}{subsection.9.4.3}
\contentsline {paragraph}{Policy Gradient}{135}{section*.182}
\contentsline {paragraph}{Variance Reduction}{136}{section*.183}
\contentsline {section}{\numberline {9.5}Simultaneous Beam Search}{137}{section.9.5}
\contentsline {section}{\numberline {9.6}Experiments}{138}{section.9.6}
\contentsline {subsection}{\numberline {9.6.1}Settings}{138}{subsection.9.6.1}
\contentsline {paragraph}{Dataset}{138}{section*.185}
\contentsline {paragraph}{Environment \& Agent Settings}{138}{section*.186}
\contentsline {paragraph}{Baselines}{138}{section*.187}
\contentsline {subsection}{\numberline {9.6.2}Quantitative Analysis}{139}{subsection.9.6.2}
\contentsline {paragraph}{Learning Curves}{139}{section*.191}
\contentsline {paragraph}{Quality v.s. Delay}{139}{section*.192}
\contentsline {paragraph}{v.s. Baselines}{142}{section*.193}
\contentsline {paragraph}{w/o Beam-Search}{143}{section*.194}
\contentsline {subsection}{\numberline {9.6.3}Qualitative Analysis}{143}{subsection.9.6.3}
\contentsline {paragraph}{EN$\rightarrow $RU}{143}{section*.197}
\contentsline {paragraph}{DE$\rightarrow $EN}{143}{section*.198}
\contentsline {section}{\numberline {9.7}Related Work}{146}{section.9.7}
\contentsline {section}{\numberline {9.8}Conclusion}{147}{section.9.8}
\contentsline {chapter}{\numberline {10}Conclusion}{148}{chapter.10}
\contentsline {section}{\numberline {10.1}Future Work}{149}{section.10.1}
\contentsline {paragraph}{Same quality, Better efficiency }{149}{section*.199}
\contentsline {paragraph}{Light-weight NMT}{150}{section*.200}
\contentsline {paragraph}{Incorporate Linguistic Information}{150}{section*.201}
